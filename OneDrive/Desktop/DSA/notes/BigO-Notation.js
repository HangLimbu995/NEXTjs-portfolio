// Big O Notation Explained
// What is Big O Notation?
// Big O notation is a mathematical concept used to describe the efficiency of an algorithm in terms of time and space complexity as the input size (n) grows.

// ğŸ’¡ Why is it important?

// Helps compare algorithms based on their performance.
// Determines how well an algorithm scales.
// Used in coding interviews and competitive programming.
// 1ï¸âƒ£ Types of Complexities in Big O
// Big O notation primarily focuses on:

// Time Complexity â³ â€“ How fast does the algorithm run?
// Space Complexity ğŸ’¾ â€“ How much memory does the algorithm use?
// 2ï¸âƒ£ Common Big O Complexities
// Big O	Name	Meaning
// O(1)	Constant Time	Stays the same regardless of input size
// O(log n)	Logarithmic Time	Reduces problem size each step (Binary Search)
// O(n)	Linear Time	Grows proportionally with input size
// O(n log n)	Linearithmic Time	Efficient sorting (Merge Sort, Quick Sort)
// O(nÂ²)	Quadratic Time	Nested loops (Bubble Sort)
// O(2â¿)	Exponential Time	Doubles at each step (Recursion-heavy problems)
// O(n!)	Factorial Time	Extremely slow (Traveling Salesman Problem)
// 3ï¸âƒ£ Examples of Each Big O Complexity
// ğŸ”¹ O(1) â€“ Constant Time
// Does not depend on input size (n).

// js
// Copy
// Edit
// function getFirstElement(arr) {
//     return arr[0];  // Always takes the same time
// }
// âœ… Fastest Complexity â€“ Even if the array has 1M elements, it still takes the same time.

// ğŸ”¹ O(log n) â€“ Logarithmic Time
// Reduces the problem size in each step (Binary Search).

// js
// Copy
// Edit
// function binarySearch(arr, target) {
//     let left = 0, right = arr.length - 1;
//     while (left <= right) {
//         let mid = Math.floor((left + right) / 2);
//         if (arr[mid] === target) return mid;
//         else if (arr[mid] < target) left = mid + 1;
//         else right = mid - 1;
//     }
//     return -1;
// }
// âœ… Efficient for large datasets (e.g., Searching in 1 billion elements takes only ~30 steps).

// ğŸ”¹ O(n) â€“ Linear Time
// Time grows directly with input size.

// js
// Copy
// Edit
// function findMax(arr) {
//     let max = arr[0];
//     for (let i = 1; i < arr.length; i++) {
//         if (arr[i] > max) {
//             max = arr[i];
//         }
//     }
//     return max;
// }
// âœ… Common for loops â€“ If n = 1000, it runs 1000 times.

// ğŸ”¹ O(n log n) â€“ Linearithmic Time
// Used in efficient sorting algorithms like Merge Sort & Quick Sort.

// js
// Copy
// Edit
// function mergeSort(arr) {
//     if (arr.length < 2) return arr;
//     let mid = Math.floor(arr.length / 2);
//     let left = mergeSort(arr.slice(0, mid));
//     let right = mergeSort(arr.slice(mid));
//     return merge(left, right);
// }
// âœ… Much faster than O(nÂ²) for large inputs.

// ğŸ”¹ O(nÂ²) â€“ Quadratic Time
// Nested loops â†’ Performance drops significantly as input grows.

// js
// Copy
// Edit
// function bubbleSort(arr) {
//     for (let i = 0; i < arr.length; i++) {
//         for (let j = 0; j < arr.length - i - 1; j++) {
//             if (arr[j] > arr[j + 1]) {
//                 [arr[j], arr[j + 1]] = [arr[j + 1], arr[j]];
//             }
//         }
//     }
//     return arr;
// }
// âŒ Bad for large inputs â€“ If n = 1000, it runs 1M (1000Â²) times.

// ğŸ”¹ O(2â¿) â€“ Exponential Time
// Every call branches into multiple calls (Recursion-heavy).

// js
// Copy
// Edit
// function fibonacci(n) {
//     if (n <= 1) return n;
//     return fibonacci(n - 1) + fibonacci(n - 2);
// }
// âŒ Very slow for large values of n â€“ Even for n = 50, it takes too long.

// ğŸ”¹ O(n!) â€“ Factorial Time
// Extreme growth â€“ Worst possible complexity.

// js
// Copy
// Edit
// function permutations(str, prefix = "") {
//     if (str.length === 0) console.log(prefix);
//     for (let i = 0; i < str.length; i++) {
//         permutations(str.slice(0, i) + str.slice(i + 1), prefix + str[i]);
//     }
// }
// âŒ Unusable for large inputs â€“ n = 10 â†’ 3.6M operations.

// 4ï¸âƒ£ Best to Worst Performance (Big O Ranking)
// âœ… Best (Fastest)

// O(1) â†’ Constant
// O(log n) â†’ Logarithmic
// O(n) â†’ Linear
// O(n log n) â†’ Linearithmic
// O(nÂ²) â†’ Quadratic
// O(2â¿) â†’ Exponential
// O(n!) â†’ Factorial
// âŒ Worst (Slowest)
// 5ï¸âƒ£ How to Analyze Time Complexity?
// 1ï¸âƒ£ Count the loops

// Single loop â†’ O(n)
// Nested loop â†’ O(nÂ²)
// Binary Search (halving) â†’ O(log n)
// 2ï¸âƒ£ Ignore Constants

// O(2n) â†’ O(n)
// O(500n) â†’ O(n)
// 3ï¸âƒ£ Drop Non-Dominant Terms

// O(nÂ² + n) â†’ O(nÂ²)
// O(n log n + n) â†’ O(n log n)
// 6ï¸âƒ£ Practical Tips
// âœ… Use Hash Tables (O(1) lookup) for fast searches
// âœ… Use Sorting (O(n log n)) before Binary Search (O(log n))
// âœ… Avoid nested loops where possible (O(nÂ²) is bad!)
// âœ… Use Recursion wisely to avoid O(2â¿) complexity

// Conclusion
// Big O helps us write efficient code! ğŸš€
// ğŸ”¹ O(1), O(log n), O(n), O(n log n) are good.
// ğŸ”¹ O(nÂ²), O(2â¿), O(n!) should be avoided for large inputs.

// Got it? âœ… Now go optimize your algorithms! ğŸ”¥